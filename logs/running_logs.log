[2024-09-28 20:06:23,004: INFO: main: Logger Developed Successfully!]
[2024-10-04 20:59:59,169: INFO: main: ####### Data Ingestion Stage has started #######]
[2024-10-04 20:59:59,212: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-04 20:59:59,311: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-04 20:59:59,313: ERROR: main: "'ConfigBox' object has no attribute '_root'"]
Traceback (most recent call last):
  File "box\box.py", line 503, in box.box.Box.__getitem__
KeyError: '_root'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\box.py", line 536, in box.box.Box.__getattr__
  File "box\box.py", line 524, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'_root'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\box.py", line 538, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute '_root'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\config_box.py", line 28, in box.config_box.ConfigBox.__getattr__
  File "box\box.py", line 552, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute '_root'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\box.py", line 503, in box.box.Box.__getitem__
KeyError: '_root'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\box.py", line 536, in box.box.Box.__getattr__
  File "box\box.py", line 524, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'_root'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\box.py", line 538, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute '_root'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 11, in <module>
    objDITP.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_01_data_ingestion.py", line 24, in main
    raise e
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_01_data_ingestion.py", line 17, in main
    config = ConfigurationManager()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\config\configuration.py", line 12, in __init__
    create_directories([self.config._root])
  File "box\config_box.py", line 30, in box.config_box.ConfigBox.__getattr__
  File "box\box.py", line 552, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute '_root'"
[2024-10-04 21:01:15,908: INFO: main: ####### Data Ingestion Stage has started #######]
[2024-10-04 21:01:15,910: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-04 21:01:15,911: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-04 21:01:15,912: INFO: common: created directory at: data]
[2024-10-04 21:01:15,913: INFO: common: created directory at: data/images]
[2024-10-04 21:01:20,338: INFO: data_ingestion: data/images/data.zip downloaded! With the following info: 
Connection: close
Content-Length: 7903594
Cache-Control: max-age=300
Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; sandbox
Content-Type: application/zip
ETag: "dbc016a060da18070593b83afff580c9b300f0b6ea4147a7988433e04df246ca"
Strict-Transport-Security: max-age=31536000
X-Content-Type-Options: nosniff
X-Frame-Options: deny
X-XSS-Protection: 1; mode=block
X-GitHub-Request-Id: D5EC:08C8:2CF6B:34BA2:67000A44
Accept-Ranges: bytes
Date: Fri, 04 Oct 2024 15:31:17 GMT
Via: 1.1 varnish
X-Served-By: cache-del21744-DEL
X-Cache: MISS
X-Cache-Hits: 0
X-Timer: S1728055877.118815,VS0,VE624
Vary: Authorization,Accept-Encoding,Origin
Access-Control-Allow-Origin: *
Cross-Origin-Resource-Policy: cross-origin
X-Fastly-Request-ID: 2c9863d56583b03287dd76c174387937452b1daa
Expires: Fri, 04 Oct 2024 15:36:17 GMT
Source-Age: 0

]
[2024-10-04 21:01:20,764: INFO: main: ####### Data Ingestion Stage is completed #######


]
[2024-10-04 21:03:00,564: INFO: main: ####### Data Ingestion Stage has started #######]
[2024-10-04 21:03:00,587: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-04 21:03:00,588: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-04 21:03:00,589: INFO: common: created directory at: data]
[2024-10-04 21:03:00,590: INFO: common: created directory at: data/text_data]
[2024-10-04 21:03:00,769: ERROR: main: [Errno 2] No such file or directory: 'data/images/data.zip']
Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 11, in <module>
    objDITP.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_01_data_ingestion.py", line 24, in main
    raise e
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_01_data_ingestion.py", line 20, in main
    data_ingestion.download_file()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\components\data_ingestion.py", line 22, in download_file
    filename, headers = request.urlretrieve(
  File "C:\Users\admin\AppData\Local\Programs\Python\Python310\lib\urllib\request.py", line 251, in urlretrieve
    tfp = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: 'data/images/data.zip'
[2024-10-04 21:03:19,488: INFO: main: ####### Data Ingestion Stage has started #######]
[2024-10-04 21:03:19,534: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-04 21:03:19,536: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-04 21:03:19,536: INFO: common: created directory at: data]
[2024-10-04 21:03:19,537: INFO: common: created directory at: data/text_data]
[2024-10-04 21:03:22,504: INFO: data_ingestion: data/text_data/data.zip downloaded! With the following info: 
Connection: close
Content-Length: 7903594
Cache-Control: max-age=300
Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; sandbox
Content-Type: application/zip
ETag: "dbc016a060da18070593b83afff580c9b300f0b6ea4147a7988433e04df246ca"
Strict-Transport-Security: max-age=31536000
X-Content-Type-Options: nosniff
X-Frame-Options: deny
X-XSS-Protection: 1; mode=block
X-GitHub-Request-Id: D5EC:08C8:2CF6B:34BA2:67000A44
Accept-Ranges: bytes
Date: Fri, 04 Oct 2024 15:33:19 GMT
Via: 1.1 varnish
X-Served-By: cache-del21727-DEL
X-Cache: HIT
X-Cache-Hits: 0
X-Timer: S1728056000.790147,VS0,VE1
Vary: Authorization,Accept-Encoding,Origin
Access-Control-Allow-Origin: *
Cross-Origin-Resource-Policy: cross-origin
X-Fastly-Request-ID: 48192a4603dc9802246c7583370dd4ddcd60a743
Expires: Fri, 04 Oct 2024 15:38:19 GMT
Source-Age: 122

]
[2024-10-04 21:03:22,828: INFO: main: ####### Data Ingestion Stage is completed #######


]
[2024-10-08 23:49:55,294: INFO: main: ####### Data Validation Stage has started #######]
[2024-10-08 23:49:55,324: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-08 23:49:55,472: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-08 23:49:55,491: INFO: common: created directory at: data]
[2024-10-08 23:49:55,492: INFO: common: created directory at: artifacts/data_validation]
[2024-10-08 23:49:55,492: ERROR: main: 'DataValidationConfig' object has no attribute 'data_ing_dir']
Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 26, in <module>
    objDVTP.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_02_data_validation.py", line 14, in main
    data_validation.validate_all_files_exist()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\components\data_validation.py", line 33, in validate_all_files_exist
    raise e
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\components\data_validation.py", line 14, in validate_all_files_exist
    all_files = os.listdir(os.path.join(self.config.data_ing_dir,"samsum_dataset"))
AttributeError: 'DataValidationConfig' object has no attribute 'data_ing_dir'
[2024-10-08 23:51:03,926: INFO: main: ####### Data Validation Stage has started #######]
[2024-10-08 23:51:03,934: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-08 23:51:03,937: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-08 23:51:03,938: INFO: common: created directory at: data]
[2024-10-08 23:51:03,941: INFO: common: created directory at: artifacts/data_validation]
[2024-10-08 23:51:03,942: ERROR: main: DataValidationConfig.__init__() missing 1 required positional argument: 'data_ing_dir']
Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 26, in <module>
    objDVTP.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_02_data_validation.py", line 12, in main
    data_validation_config = config.get_data_validation_config()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\config\configuration.py", line 36, in get_data_validation_config
    data_validation_config = DataValidationConfig(
TypeError: DataValidationConfig.__init__() missing 1 required positional argument: 'data_ing_dir'
[2024-10-08 23:51:40,054: INFO: main: ####### Data Validation Stage has started #######]
[2024-10-08 23:51:40,060: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-08 23:51:40,064: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-08 23:51:40,066: INFO: common: created directory at: data]
[2024-10-08 23:51:40,067: INFO: common: created directory at: artifacts/data_validation]
[2024-10-08 23:51:40,650: INFO: main: ####### Data Validation Stage is completed #######


]
[2024-10-08 23:53:10,011: INFO: main: ####### Data Validation Stage has started #######]
[2024-10-08 23:53:10,038: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-08 23:53:10,042: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-08 23:53:10,045: INFO: common: created directory at: data]
[2024-10-08 23:53:10,049: INFO: common: created directory at: data/data_validation]
[2024-10-08 23:53:10,053: INFO: main: ####### Data Validation Stage is completed #######


]
[2024-10-09 00:02:22,043: INFO: main: ####### Data Validation Stage has started #######]
[2024-10-09 00:02:22,068: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-09 00:02:22,105: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-09 00:02:22,108: INFO: common: created directory at: data]
[2024-10-09 00:02:22,110: INFO: common: created directory at: data/data_validation]
[2024-10-09 00:02:22,121: INFO: main: ####### Data Validation Stage is completed #######


]
[2024-10-09 00:03:10,336: INFO: main: ####### Data Validation Stage has started #######]
[2024-10-09 00:03:10,340: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-09 00:03:10,343: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-09 00:03:10,344: INFO: common: created directory at: data]
[2024-10-09 00:03:10,345: INFO: common: created directory at: data/data_validation]
[2024-10-09 00:03:10,348: INFO: main: ####### Data Validation Stage is completed #######


]
[2024-10-11 16:33:20,016: INFO: config: PyTorch version 2.4.1 available.]
[2024-10-11 16:33:24,465: INFO: main: ####### Data Transformation Stage has started #######]
[2024-10-11 16:33:24,482: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-11 16:33:24,544: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-11 16:33:24,586: INFO: common: created directory at: data]
[2024-10-11 16:33:24,599: INFO: common: created directory at: data/data_transformation/samsum_dataset]
[2024-10-11 16:33:32,531: ERROR: main: 'DataTransformationConfig' object has no attribute 'data_path']
Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 40, in <module>
    objDTTP.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_03_data_transformation.py", line 14, in main
    data_transformation.convert()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\components\data_transformation.py", line 30, in convert
    dataset_samsum = load_from_disk(self.config.data_path)
AttributeError: 'DataTransformationConfig' object has no attribute 'data_path'
[2024-10-11 16:48:49,022: INFO: config: PyTorch version 2.4.1 available.]
[2024-10-11 16:48:49,502: INFO: main: ####### Data Transformation Stage has started #######]
[2024-10-11 16:48:49,502: INFO: stage_03_data_transformation: Setting Config Object...]
[2024-10-11 16:48:49,502: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-11 16:48:49,507: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-11 16:48:49,507: INFO: common: created directory at: data]
[2024-10-11 16:48:49,507: INFO: stage_03_data_transformation: Reading configs...]
[2024-10-11 16:48:49,507: INFO: common: created directory at: data/data_transformation/samsum_dataset]
[2024-10-11 16:48:49,507: INFO: stage_03_data_transformation: Data Transforming Object...]
[2024-10-11 16:48:51,180: INFO: data_transformation: Loading Data...]
[2024-10-11 16:48:52,118: INFO: data_transformation: Transforming Data...]
[2024-10-11 16:48:52,256: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:52,520: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:52,840: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:53,071: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:53,230: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:53,445: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:53,612: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:53,821: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:53,960: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:54,205: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:54,350: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:54,523: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:54,655: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:54,841: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:54,975: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:55,150: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:55,382: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:55,556: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:55,694: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:55,870: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:56,016: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:56,201: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:56,324: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:56,510: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:56,634: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:56,801: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:56,940: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:57,161: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:57,281: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:57,410: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:57,570: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:57,721: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:57,871: INFO: data_transformation: Creating Input Encodings...]
[2024-10-11 16:48:58,036: INFO: data_transformation: Creating Target Encodings...]
[2024-10-11 16:48:58,281: INFO: data_transformation: Saving Transformed Data...]
[2024-10-11 16:48:58,497: INFO: main: ####### Data Transformation Stage is completed #######


]
[2024-10-12 16:55:50,198: INFO: config: PyTorch version 2.4.1 available.]
[2024-10-12 16:59:18,769: INFO: config: PyTorch version 2.4.1 available.]
[2024-10-12 16:59:37,929: INFO: main: ####### Model Training Stage has started #######]
[2024-10-12 16:59:38,803: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-12 16:59:38,952: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-12 16:59:38,974: INFO: common: created directory at: data]
[2024-10-12 16:59:38,975: ERROR: main: 'ConfigurationManager' object has no attribute 'get_model_trainer_config']
Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 54, in <module>
    objMTP.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_04_model_training.py", line 12, in main
    model_trainer_config = config.get_model_trainer_config()
AttributeError: 'ConfigurationManager' object has no attribute 'get_model_trainer_config'
[2024-10-12 17:25:33,962: INFO: config: PyTorch version 2.4.1 available.]
[2024-10-12 17:25:43,639: INFO: main: ####### Model Training Stage has started #######]
[2024-10-12 17:25:43,667: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-12 17:25:43,714: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-12 17:25:43,722: INFO: common: created directory at: data]
[2024-10-12 17:25:43,722: ERROR: main: "'ConfigBox' object has no attribute 'model_trainer'"]
Traceback (most recent call last):
  File "box\box.py", line 503, in box.box.Box.__getitem__
KeyError: 'model_trainer'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\box.py", line 536, in box.box.Box.__getattr__
  File "box\box.py", line 524, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'model_trainer'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\box.py", line 538, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'model_trainer'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\config_box.py", line 28, in box.config_box.ConfigBox.__getattr__
  File "box\box.py", line 552, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'model_trainer'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\box.py", line 503, in box.box.Box.__getitem__
KeyError: 'model_trainer'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\box.py", line 536, in box.box.Box.__getattr__
  File "box\box.py", line 524, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'model_trainer'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\box.py", line 538, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'model_trainer'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 54, in <module>
    objMTP.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_04_model_training.py", line 12, in main
    model_trainer_config = config.get_model_training_config()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\config\configuration.py", line 61, in get_model_training_config
    config = self.config.model_trainer
  File "box\config_box.py", line 30, in box.config_box.ConfigBox.__getattr__
  File "box\box.py", line 552, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'model_trainer'"
[2024-10-12 17:27:11,698: INFO: config: PyTorch version 2.4.1 available.]
[2024-10-12 17:27:12,990: INFO: main: ####### Model Training Stage has started #######]
[2024-10-12 17:27:12,995: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-12 17:27:12,995: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-12 17:27:12,995: INFO: common: created directory at: data]
[2024-10-12 17:27:13,000: INFO: common: created directory at: data/trained_model]
[2024-10-12 17:27:13,000: ERROR: main: "'ConfigBox' object has no attribute 'data_path'"]
Traceback (most recent call last):
  File "box\box.py", line 503, in box.box.Box.__getitem__
KeyError: 'data_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\box.py", line 536, in box.box.Box.__getattr__
  File "box\box.py", line 524, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'data_path'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\box.py", line 538, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'data_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\config_box.py", line 28, in box.config_box.ConfigBox.__getattr__
  File "box\box.py", line 552, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'data_path'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\box.py", line 503, in box.box.Box.__getitem__
KeyError: 'data_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\box.py", line 536, in box.box.Box.__getattr__
  File "box\box.py", line 524, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'data_path'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\box.py", line 538, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'data_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 54, in <module>
    objMTP.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_04_model_training.py", line 12, in main
    model_trainer_config = config.get_model_training_config()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\config\configuration.py", line 68, in get_model_training_config
    data_path=config.data_path,
  File "box\config_box.py", line 30, in box.config_box.ConfigBox.__getattr__
  File "box\box.py", line 552, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'data_path'"
[2024-10-12 17:28:02,283: INFO: config: PyTorch version 2.4.1 available.]
[2024-10-12 17:28:03,604: INFO: main: ####### Model Training Stage has started #######]
[2024-10-12 17:28:03,604: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-12 17:28:03,609: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-12 17:28:03,609: INFO: common: created directory at: data]
[2024-10-12 17:28:03,609: INFO: common: created directory at: data/trained_model]
[2024-10-12 17:28:03,609: ERROR: main: ModelTrainingConfig.__init__() got an unexpected keyword argument 'root_dir']
Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 54, in <module>
    objMTP.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_04_model_training.py", line 12, in main
    model_trainer_config = config.get_model_training_config()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\config\configuration.py", line 66, in get_model_training_config
    model_training_config = ModelTrainingConfig(
TypeError: ModelTrainingConfig.__init__() got an unexpected keyword argument 'root_dir'
[2024-10-12 17:29:53,816: INFO: config: PyTorch version 2.4.1 available.]
[2024-10-12 17:29:55,548: INFO: main: ####### Model Training Stage has started #######]
[2024-10-12 17:29:55,553: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-12 17:29:55,553: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-12 17:29:55,553: INFO: common: created directory at: data]
[2024-10-12 17:29:55,557: INFO: common: created directory at: data/trained_model]
[2024-10-12 17:29:55,557: ERROR: main: ModelTrainingConfig.__init__() got an unexpected keyword argument 'data_ing_path']
Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 54, in <module>
    objMTP.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_04_model_training.py", line 12, in main
    model_trainer_config = config.get_model_training_config()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\config\configuration.py", line 66, in get_model_training_config
    model_training_config = ModelTrainingConfig(
TypeError: ModelTrainingConfig.__init__() got an unexpected keyword argument 'data_ing_path'
[2024-10-12 17:30:43,961: INFO: config: PyTorch version 2.4.1 available.]
[2024-10-12 17:30:45,202: INFO: main: ####### Model Training Stage has started #######]
[2024-10-12 17:30:45,207: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-10-12 17:30:45,207: INFO: common: YAML file: params.yaml loaded successfully]
[2024-10-12 17:30:45,212: INFO: common: created directory at: data]
[2024-10-12 17:30:45,212: INFO: common: created directory at: data/trained_model]
[2024-10-12 17:30:45,212: INFO: model_training: Initializing Model...]
[2024-11-07 18:37:42,242: INFO: config: PyTorch version 2.4.1 available.]
[2024-11-07 18:38:09,281: INFO: main: ####### Data Transformation Stage has started #######]
[2024-11-07 18:38:09,286: INFO: stage_03_data_transformation: Setting Config Object...]
[2024-11-07 18:38:09,448: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-11-07 18:38:09,538: INFO: common: YAML file: params.yaml loaded successfully]
[2024-11-07 18:38:09,598: INFO: common: created directory at: data]
[2024-11-07 18:38:09,601: INFO: stage_03_data_transformation: Reading configs...]
[2024-11-07 18:38:09,604: INFO: common: created directory at: data/data_transformation/samsum_dataset]
[2024-11-07 18:38:09,605: INFO: stage_03_data_transformation: Data Transforming Object...]
[2024-11-07 18:38:16,136: INFO: data_transformation: Loading Data...]
[2024-11-07 18:38:17,511: INFO: data_transformation: Transforming Data...]
[2024-11-07 18:38:18,038: INFO: data_transformation: Creating Input Encodings...]
[2024-11-07 18:38:18,233: INFO: data_transformation: Creating Target Encodings...]
[2024-11-07 18:38:19,289: INFO: data_transformation: Saving Transformed Data...]
[2024-11-07 18:38:19,586: INFO: main: ####### Data Transformation Stage is completed #######


]
[2024-11-08 17:30:37,570: INFO: config: PyTorch version 2.4.1 available.]
[2024-11-08 17:30:49,548: INFO: main: ####### Data Transformation Stage has started #######]
[2024-11-08 17:30:49,553: INFO: stage_03_data_transformation: Setting Config Object...]
[2024-11-08 17:30:49,576: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-11-08 17:30:49,619: INFO: common: YAML file: params.yaml loaded successfully]
[2024-11-08 17:30:49,624: INFO: common: created directory at: data]
[2024-11-08 17:30:49,625: INFO: stage_03_data_transformation: Reading configs...]
[2024-11-08 17:30:49,626: INFO: common: created directory at: data/data_transformation/samsum_dataset]
[2024-11-08 17:30:49,631: INFO: stage_03_data_transformation: Data Transforming Object...]
[2024-11-08 17:30:53,885: INFO: data_transformation: Loading Data...]
[2024-11-08 17:30:54,329: INFO: data_transformation: Transforming Data...]
[2024-11-08 17:30:55,166: INFO: data_transformation: Creating Input Encodings...]
[2024-11-08 17:30:55,503: INFO: data_transformation: Creating Target Encodings...]
[2024-11-08 17:30:56,652: INFO: data_transformation: Saving Transformed Data...]
[2024-11-08 17:30:57,083: INFO: main: ####### Data Transformation Stage is completed #######


]
[2024-12-04 14:50:35,334: INFO: server: Started server process [14316]]
[2024-12-04 14:50:35,343: INFO: on: Waiting for application startup.]
[2024-12-04 14:50:35,370: INFO: on: Application startup complete.]
[2024-12-04 14:50:35,372: INFO: server: Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)]
[2024-12-04 14:52:31,851: INFO: config: PyTorch version 2.4.1 available.]
[2024-12-04 15:45:19,132: INFO: server: Shutting down]
[2024-12-04 15:45:19,238: INFO: on: Waiting for application shutdown.]
[2024-12-04 15:45:19,240: INFO: on: Application shutdown complete.]
[2024-12-04 15:45:19,241: INFO: server: Finished server process [14316]]
[2024-12-04 16:35:52,702: INFO: config: PyTorch version 2.4.1 available.]
[2024-12-04 16:39:30,612: INFO: config: PyTorch version 2.4.1 available.]
[2024-12-04 16:40:03,741: INFO: config: PyTorch version 2.4.1 available.]
[2024-12-04 16:40:29,298: INFO: config: PyTorch version 2.4.1 available.]
[2024-12-04 16:40:31,674: INFO: main: ####### Data Transformation Stage has started #######]
[2024-12-04 16:40:31,679: INFO: stage_03_data_transformation: Setting Config Object...]
[2024-12-04 16:40:31,691: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-12-04 16:40:32,135: INFO: common: YAML file: params.yaml loaded successfully]
[2024-12-04 16:40:32,255: INFO: common: created directory at: data]
[2024-12-04 16:40:32,257: INFO: stage_03_data_transformation: Reading configs...]
[2024-12-04 16:40:32,260: INFO: common: created directory at: data/data_transformation/samsum_dataset]
[2024-12-04 16:40:32,261: INFO: stage_03_data_transformation: Data Transforming Object...]
[2024-12-04 16:40:39,882: INFO: data_transformation: Loading Data...]
[2024-12-04 16:40:41,071: INFO: data_transformation: Transforming Data...]
[2024-12-04 16:40:41,125: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:40:41,394: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:40:42,038: ERROR: main: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).]
Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 775, in convert_to_tensors
    tensor = as_tensor(value)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 737, in as_tensor
    return torch.tensor(value)
ValueError: expected sequence of length 12 at dim 1 (got 13)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 41, in <module>
    objDTTP.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_03_data_transformation.py", line 19, in main
    data_transformation.convert()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\components\data_transformation.py", line 38, in convert
    dataset_samsum_pt = dataset_samsum.map(self.convert_examples_to_features, batched = True)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\datasets\dataset_dict.py", line 866, in map
    {
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\datasets\dataset_dict.py", line 867, in <dictcomp>
    k: dataset.map(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\datasets\arrow_dataset.py", line 560, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\datasets\arrow_dataset.py", line 3035, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\datasets\arrow_dataset.py", line 3438, in _map_single
    batch = apply_function_on_filtered_inputs(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\datasets\arrow_dataset.py", line 3300, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\components\data_transformation.py", line 24, in convert_examples_to_features
    target_encodings = self.tokenizer(example_batch['summary'], return_tensors="pt", max_length = 128, truncation = True )
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 3024, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 3112, in _call_one
    return self.batch_encode_plus(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 3314, in batch_encode_plus
    return self._batch_encode_plus(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_fast.py", line 577, in _batch_encode_plus
    return BatchEncoding(sanitized_tokens, sanitized_encodings, tensor_type=return_tensors)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 240, in __init__
    self.convert_to_tensors(tensor_type=tensor_type, prepend_batch_axis=prepend_batch_axis)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 791, in convert_to_tensors
    raise ValueError(
ValueError: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).
[2024-12-04 16:43:57,632: INFO: config: PyTorch version 2.4.1 available.]
[2024-12-04 16:43:58,990: INFO: main: ####### Data Transformation Stage has started #######]
[2024-12-04 16:43:58,994: INFO: stage_03_data_transformation: Setting Config Object...]
[2024-12-04 16:43:58,997: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-12-04 16:43:59,000: INFO: common: YAML file: params.yaml loaded successfully]
[2024-12-04 16:43:59,001: INFO: common: created directory at: data]
[2024-12-04 16:43:59,001: INFO: stage_03_data_transformation: Reading configs...]
[2024-12-04 16:43:59,002: INFO: common: created directory at: data/data_transformation/samsum_dataset]
[2024-12-04 16:43:59,002: INFO: stage_03_data_transformation: Data Transforming Object...]
[2024-12-04 16:44:00,348: INFO: data_transformation: Loading Data...]
[2024-12-04 16:44:00,378: INFO: data_transformation: Transforming Data...]
[2024-12-04 16:44:00,763: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:44:03,904: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:44:04,549: ERROR: main: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).]
Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 775, in convert_to_tensors
    tensor = as_tensor(value)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 737, in as_tensor
    return torch.tensor(value)
ValueError: expected sequence of length 12 at dim 1 (got 13)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 41, in <module>
    objDTTP.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_03_data_transformation.py", line 19, in main
    data_transformation.convert()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\components\data_transformation.py", line 38, in convert
    dataset_samsum_pt = dataset_samsum.map(self.convert_examples_to_features, batched = True)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\datasets\dataset_dict.py", line 866, in map
    {
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\datasets\dataset_dict.py", line 867, in <dictcomp>
    k: dataset.map(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\datasets\arrow_dataset.py", line 560, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\datasets\arrow_dataset.py", line 3035, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\datasets\arrow_dataset.py", line 3438, in _map_single
    batch = apply_function_on_filtered_inputs(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\datasets\arrow_dataset.py", line 3300, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\components\data_transformation.py", line 24, in convert_examples_to_features
    target_encodings = self.tokenizer(example_batch['summary'], return_tensors="pt", max_length = 128, truncation = True )
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 3024, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 3112, in _call_one
    return self.batch_encode_plus(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 3314, in batch_encode_plus
    return self._batch_encode_plus(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils.py", line 889, in _batch_encode_plus
    batch_outputs = self._batch_prepare_for_model(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils.py", line 976, in _batch_prepare_for_model
    batch_outputs = BatchEncoding(batch_outputs, tensor_type=return_tensors)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 240, in __init__
    self.convert_to_tensors(tensor_type=tensor_type, prepend_batch_axis=prepend_batch_axis)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\tokenization_utils_base.py", line 791, in convert_to_tensors
    raise ValueError(
ValueError: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).
[2024-12-04 16:47:50,640: INFO: config: PyTorch version 2.4.1 available.]
[2024-12-04 16:47:52,626: INFO: main: ####### Data Transformation Stage has started #######]
[2024-12-04 16:47:52,627: INFO: stage_03_data_transformation: Setting Config Object...]
[2024-12-04 16:47:52,634: INFO: common: YAML file: config\config.yaml loaded successfully]
[2024-12-04 16:47:52,643: INFO: common: YAML file: params.yaml loaded successfully]
[2024-12-04 16:47:52,646: INFO: common: created directory at: data]
[2024-12-04 16:47:52,647: INFO: stage_03_data_transformation: Reading configs...]
[2024-12-04 16:47:52,648: INFO: common: created directory at: data/data_transformation/samsum_dataset]
[2024-12-04 16:47:52,649: INFO: stage_03_data_transformation: Data Transforming Object...]
[2024-12-04 16:47:54,017: INFO: data_transformation: Loading Data...]
[2024-12-04 16:47:54,040: INFO: data_transformation: Transforming Data...]
[2024-12-04 16:47:54,419: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:47:56,624: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:47:58,014: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:00,928: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:01,629: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:04,426: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:05,031: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:07,180: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:07,924: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:10,146: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:10,789: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:12,877: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:13,435: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:15,531: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:17,055: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:19,129: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:19,783: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:22,014: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:22,571: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:24,899: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:25,485: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:27,628: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:28,304: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:30,498: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:31,037: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:33,512: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:34,153: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:36,362: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:37,018: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:38,708: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:39,743: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:41,883: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:43,053: INFO: data_transformation: Creating Input Encodings...]
[2024-12-04 16:48:45,849: INFO: data_transformation: Creating Target Encodings...]
[2024-12-04 16:48:46,560: INFO: data_transformation: Saving Transformed Data...]
[2024-12-04 16:48:46,761: INFO: main: ####### Data Transformation Stage is completed #######


]
[2025-01-03 16:14:53,181: INFO: config: PyTorch version 2.4.1 available.]
[2025-01-03 17:37:25,982: INFO: config: PyTorch version 2.4.1 available.]
[2025-01-03 17:49:09,319: INFO: config: PyTorch version 2.4.1 available.]
[2025-01-03 17:49:30,914: INFO: main: ####### Model Evaluation Stage has started #######]
[2025-01-03 17:49:30,975: INFO: common: YAML file: config\config.yaml loaded successfully]
[2025-01-03 17:49:31,029: INFO: common: YAML file: params.yaml loaded successfully]
[2025-01-03 17:49:31,037: INFO: common: created directory at: data]
[2025-01-03 17:49:31,037: INFO: common: created directory at: data/model_evaluation]
[2025-01-03 17:49:31,037: ERROR: main: Incorrect path_or_model_id: 'data/trained_model/tokenizer'. Please provide either the path to a local folder or the repo_id of a model on the Hub.]
Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\utils\hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\huggingface_hub\utils\_deprecation.py", line 101, in inner_f
    return f(*args, **kwargs)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\huggingface_hub\utils\_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\huggingface_hub\utils\_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'data/trained_model/tokenizer'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 66, in <module>
    objME.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_05_model_evaluation.py", line 14, in main
    model_evaluation_config.evaluate()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\components\model_evaluation.py", line 40, in evaluate
    tokenizer = AutoTokenizer.from_pretrained(self.config.tokenizer_path)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\models\auto\tokenization_auto.py", line 844, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\models\auto\tokenization_auto.py", line 676, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\utils\hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: 'data/trained_model/tokenizer'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
[2025-01-03 17:51:33,587: INFO: config: PyTorch version 2.4.1 available.]
[2025-01-03 17:51:53,469: INFO: main: ####### Model Evaluation Stage has started #######]
[2025-01-03 17:51:53,474: INFO: common: YAML file: config\config.yaml loaded successfully]
[2025-01-03 17:51:53,480: INFO: common: YAML file: params.yaml loaded successfully]
[2025-01-03 17:51:53,482: INFO: common: created directory at: data]
[2025-01-03 17:51:53,483: INFO: common: created directory at: data/model_evaluation]
[2025-01-03 17:51:53,484: ERROR: main: Incorrect path_or_model_id: 'data/trained_model/tokenizer'. Please provide either the path to a local folder or the repo_id of a model on the Hub.]
Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\utils\hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\huggingface_hub\utils\_deprecation.py", line 101, in inner_f
    return f(*args, **kwargs)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\huggingface_hub\utils\_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\huggingface_hub\utils\_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'data/trained_model/tokenizer'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 66, in <module>
    objME.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_05_model_evaluation.py", line 14, in main
    model_evaluation_config.evaluate()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\components\model_evaluation.py", line 40, in evaluate
    tokenizer = AutoTokenizer.from_pretrained(self.config.tokenizer_path)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\models\auto\tokenization_auto.py", line 844, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\models\auto\tokenization_auto.py", line 676, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\utils\hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: 'data/trained_model/tokenizer'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
[2025-01-03 19:05:04,908: INFO: config: PyTorch version 2.4.1 available.]
[2025-01-03 19:05:20,026: INFO: main: ####### Model Evaluation Stage has started #######]
[2025-01-03 19:05:20,049: INFO: common: YAML file: config\config.yaml loaded successfully]
[2025-01-03 19:05:20,078: INFO: common: YAML file: params.yaml loaded successfully]
[2025-01-03 19:05:20,080: INFO: common: created directory at: data]
[2025-01-03 19:05:20,081: INFO: common: created directory at: data/model_evaluation]
[2025-01-03 19:05:20,674: ERROR: main: Incorrect path_or_model_id: 'data/trained_model/pegasus-samsum-model'. Please provide either the path to a local folder or the repo_id of a model on the Hub.]
Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\utils\hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\huggingface_hub\utils\_deprecation.py", line 101, in inner_f
    return f(*args, **kwargs)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\huggingface_hub\utils\_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\huggingface_hub\utils\_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'data/trained_model/pegasus-samsum-model'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Projects\NLP\Text Summarization\Project Files\main.py", line 66, in <module>
    objME.main()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\pipeline\stage_05_model_evaluation.py", line 14, in main
    model_evaluation_config.evaluate()
  File "d:\projects\nlp\text summarization\project files\src\text_summarization\components\model_evaluation.py", line 41, in evaluate
    model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_path).to(device)
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\models\auto\auto_factory.py", line 487, in from_pretrained
    resolved_config_file = cached_file(
  File "D:\Projects\NLP\Text Summarization\Project Files\text_summarization_proj\lib\site-packages\transformers\utils\hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: 'data/trained_model/pegasus-samsum-model'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
[2025-01-03 19:06:45,433: INFO: config: PyTorch version 2.4.1 available.]
[2025-01-03 19:06:47,740: INFO: main: ####### Model Evaluation Stage has started #######]
[2025-01-03 19:06:47,746: INFO: common: YAML file: config\config.yaml loaded successfully]
[2025-01-03 19:06:47,754: INFO: common: YAML file: params.yaml loaded successfully]
[2025-01-03 19:06:47,755: INFO: common: created directory at: data]
[2025-01-03 19:06:47,756: INFO: common: created directory at: data/model_evaluation]
[2025-01-03 19:38:51,486: INFO: rouge_scorer: Using default tokenizer.]
[2025-01-03 19:40:50,435: INFO: main: ####### Model Evaluation Stage is completed #######


]
